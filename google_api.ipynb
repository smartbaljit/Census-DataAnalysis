{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from statistics import mean\n",
    "\n",
    "# I could not figure out all those \"attempt to modify a slice of a view\" warnings.\n",
    "# I may be doing some things in a non-ideal way, but they are working.\n",
    "# Writing code that not only works but works well will have to be a future task.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# Google developer API key\n",
    "from config import google_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable to indicate if we need to call google api or not\n",
    "# if not, will assume csv files exist and data can be pulled from there, not api\n",
    "api_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice NJ data down to only Essex county, our sample set for correlation testing\n",
    "# Below data was generated via calls to the Census API, which is in the census_api.ipynb\n",
    "census_csv = \"Resources/NJ_Census_Coord_Data.csv\"\n",
    "\n",
    "census_nj_df = pd.read_csv(census_csv, index_col=0)\n",
    "census_essex_df = census_nj_df[census_nj_df[\"County\"] == \"Essex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google api call function\n",
    "# will write to a csv upon completion so we do not have to keep calling the api\n",
    "\n",
    "def get_google_data(in_census_df, out_census_csv):\n",
    "    # new lists to hold average price and average rating for each zip code\n",
    "    avg_price_data = []\n",
    "    avg_ratings_data = []\n",
    "\n",
    "    # iterate through each zip code of input dataframe\n",
    "    for index, row in in_census_df.iterrows():\n",
    "        # google places cannot search by zip code, so pass coordinates of zip code\n",
    "        target_coordinates = str(row[\"Latitude\"]) + \", \" + str(row[\"Longitude\"])\n",
    "    \n",
    "        # look for restaurants\n",
    "        target_type = \"restaurant\"\n",
    "        \n",
    "        # interested in restaurants closest to coordinates\n",
    "        # default is some kind of google ranking of restaurants that can\n",
    "        # jump around a bit, geographically\n",
    "        # we want to try to keep this as objective as possible and get closest restaurants,\n",
    "        # not google recommended restaurants that may be in next town over\n",
    "        target_rankby = \"distance\"        \n",
    "\n",
    "        # set up a parameters dictionary\n",
    "        params = {\n",
    "            \"location\": target_coordinates,\n",
    "            \"rankby\": target_rankby,\n",
    "            \"type\": target_type,\n",
    "            \"key\": google_api_key\n",
    "        }\n",
    "\n",
    "        # base url\n",
    "        base_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "        # run a request using our params dictionary\n",
    "        response = requests.get(base_url, params=params)    \n",
    "    \n",
    "        # turn it into a json\n",
    "        response_json = response.json()\n",
    "    \n",
    "        # make sure we got results\n",
    "        try:\n",
    "            num_results = len(response_json[\"results\"])\n",
    "        except KeyError:\n",
    "            num_results = 0\n",
    "    \n",
    "        # new lists to hold prices and ratings of individual restaurants\n",
    "        prices = []\n",
    "        ratings = []    \n",
    "    \n",
    "        if num_results > 0:\n",
    "            results_df = response_json[\"results\"]\n",
    "            \n",
    "            # loop through results for zip code\n",
    "            for result_loop in range(len(results_df)):\n",
    "                try:\n",
    "                    # append price to list\n",
    "                    prices.append(results_df[result_loop][\"price_level\"])                    \n",
    "                except KeyError:\n",
    "                    # if no price for this restaurant, just move along\n",
    "                    pass\n",
    "            \n",
    "                try:\n",
    "                    # append rating to list\n",
    "                    ratings.append(results_df[result_loop][\"rating\"])\n",
    "                except KeyError:\n",
    "                    # if no rating for this restaurant, just move along\n",
    "                    pass\n",
    "        \n",
    "            # calculate average of restaurant prices for zip code\n",
    "            if len(prices) > 0:\n",
    "                price_mean = mean(prices)\n",
    "            else:\n",
    "                price_mean = 0\n",
    "            \n",
    "            # append this average for zip code to list of all zip codes\n",
    "            avg_price_data.append(price_mean)\n",
    "            \n",
    "            # calculate average of restaurant ratings for zip code\n",
    "            if len(ratings) > 0:\n",
    "                ratings_mean = mean(ratings)\n",
    "            else:\n",
    "                ratings_mean = 0\n",
    "            \n",
    "            # append this average for zip code to list of all zip codes\n",
    "            avg_ratings_data.append(ratings_mean)\n",
    "    \n",
    "    # add averages for each zip code to input dataframe\n",
    "    in_census_df[\"Average Price\"] = avg_price_data\n",
    "    in_census_df[\"Average Rating\"] = avg_ratings_data\n",
    "    \n",
    "    # output to csv, so we do not have to run this api again\n",
    "    in_census_df.to_csv(out_census_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if api_needed == True:\n",
    "    get_google_data(census_essex_df, \"Resources/NJ_Census_Google_Essex.csv\")\n",
    "else:\n",
    "    census_essex_df = pd.read_csv(\"Resources/NJ_Census_Google_Essex.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Price</th>\n",
       "      <th>Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Median Age</th>\n",
       "      <td>0.471073</td>\n",
       "      <td>0.269420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Household Income</th>\n",
       "      <td>0.618979</td>\n",
       "      <td>0.429359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foreign Percentage</th>\n",
       "      <td>-0.262561</td>\n",
       "      <td>-0.146734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Price</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Rating</th>\n",
       "      <td>0.011307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Average Price  Average Rating\n",
       "Median Age               0.471073        0.269420\n",
       "Household Income         0.618979        0.429359\n",
       "Foreign Percentage      -0.262561       -0.146734\n",
       "Average Price            1.000000        0.011307\n",
       "Average Rating           0.011307        1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slice out columns we are interested in and do a pandas dataframe correlation\n",
    "# Baljit is doing graphing of this data that will tell story better,\n",
    "# but I wanted some R numbers for the correlations\n",
    "\n",
    "slice_df = census_essex_df[[\"Median Age\", \"Household Income\", \"Foreign Percentage\", \"Average Price\", \"Average Rating\"]]\n",
    "slice_corr_df = slice_df.corr()\n",
    "slice_corr_df = slice_corr_df.drop(columns=[\"Median Age\", \"Household Income\", \"Foreign Percentage\"])\n",
    "slice_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several zip codes with low population have a negative household income,\n",
    "# usually accompanied by a few other fields with bad data.\n",
    "# Slice them out. The data is incomplete and the populations small enough,\n",
    "# that it should have minimal effects on our conculsions\n",
    "\n",
    "clean_nj_df = census_nj_df[(census_nj_df[\"Household Income\"] >= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort nj zip codes by median age.\n",
    "# place top and bottom 25 zip codes in dataframes\n",
    "\n",
    "age_df = clean_nj_df.sort_values(\"Median Age\")\n",
    "age_young_df = age_df.head(25)\n",
    "age_old_df = age_df.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort nj zip codes by household income.\n",
    "# place top and bottom 25 zip codes in dataframes\n",
    "\n",
    "income_df = clean_nj_df.sort_values(\"Household Income\")\n",
    "income_poor_df = income_df.head(25)\n",
    "income_rich_df = income_df.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort nj zip codes by percentage of foreign born residents.\n",
    "# place top and bottom 25 zip codes in dataframes\n",
    "\n",
    "foreign_df = clean_nj_df.sort_values(\"Foreign Percentage\")\n",
    "foreign_low_df = foreign_df.head(25)\n",
    "foreign_high_df = foreign_df.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add restaurant price and ratings data, either via api or from previously built csv\n",
    "if api_needed == True:\n",
    "    get_google_data(age_young_df, \"Resources/NJ_Age_Young_Data.csv\")\n",
    "else:\n",
    "    age_young_df = pd.read_csv(\"Resources/NJ_Age_Young_Data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add restaurant price and ratings data, either via api or from previously built csv\n",
    "if api_needed == True:\n",
    "    get_google_data(age_old_df, \"Resources/NJ_Age_Old_Data.csv\")\n",
    "else:\n",
    "    age_old_df = pd.read_csv(\"Resources/NJ_Age_Old_Data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add restaurant price and ratings data, either via api or from previously built csv\n",
    "if api_needed == True:\n",
    "    get_google_data(income_poor_df, \"Resources/NJ_Income_Poor_Data.csv\")\n",
    "else:\n",
    "    income_poor_df = pd.read_csv(\"Resources/NJ_Income_Poor_Data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add restaurant price and ratings data, either via api or from previously built csv\n",
    "if api_needed == True:\n",
    "    get_google_data(income_rich_df, \"Resources/NJ_Income_Rich_Data.csv\")\n",
    "else:\n",
    "    income_rich_df = pd.read_csv(\"Resources/NJ_Income_Rich_Data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add restaurant price and ratings data, either via api or from previously built csv\n",
    "if api_needed == True:\n",
    "    get_google_data(foreign_low_df, \"Resources/NJ_Foreign_Low_Data.csv\")\n",
    "else:\n",
    "    foreign_low_df = pd.read_csv(\"Resources/NJ_Foreign_Low_Data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add restaurant price and ratings data, either via api or from previously built csv\n",
    "if api_needed == True:\n",
    "    get_google_data(foreign_high_df, \"Resources/NJ_Foreign_High_Data.csv\")\n",
    "else:\n",
    "    foreign_high_df = pd.read_csv(\"Resources/NJ_Foreign_High_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
